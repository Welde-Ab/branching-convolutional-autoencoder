{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified patcher for classification _ Patch PaviaU, PaviaC, Salinas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from random import shuffle\n",
    "import h5py\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io as sio # Scipy input and output\n",
    "import scipy.ndimage \n",
    "from skimage.transform import rotate \n",
    "import spectral # Module for processing hyperspectral image data.\n",
    "import matplotlib \n",
    "%matplotlib inline\n",
    "\n",
    "# scikit-learn imports \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# keras imports \n",
    "#import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ConvLSTM2D, TimeDistributed\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import sys\n",
    "import pathlib\n",
    "import spectral\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "### Limit GPU Memory growth ###\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [bar_2013, bar_2014, bar_ch_gt, hermi_2004, hermi_2007, hermi_ch_gt, bay_2013, bay_2015, bay_ch_gt_2, bay_ch_gt_ol, river_before, river_after, river_ch_gt, data1_2009, data1_2015, data1_ch_gt, data2_2009, data2_2015]:\n",
    "#     print(\"List of dictionary keys: \")\n",
    "#     key = list(i.keys());\n",
    "#     print(key);\n",
    "#     print(\"List of dictionary values\")\n",
    "#     for j in range(len(key) - 1):\n",
    "#          print(i[key[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pavU = sio.loadmat(r\"E:\\Hyperspectral Image Datasets\\ehu_datasets\\PaviaU.mat\")[\"paviaU\"]\n",
    "pavU_gt = sio.loadmat(r\"E:\\Hyperspectral Image Datasets\\ehu_datasets\\PaviaU_gt.mat\")[\"paviaU_gt\"]\n",
    "pavC = sio.loadmat(r\"E:\\Hyperspectral Image Datasets\\ehu_datasets\\Pavia.mat\")[\"pavia\"]\n",
    "pavC_gt = sio.loadmat(r\"E:\\Hyperspectral Image Datasets\\ehu_datasets\\Pavia_gt.mat\")[\"pavia_gt\"]\n",
    "sali = sio.loadmat(r\"E:\\Hyperspectral Image Datasets\\ehu_datasets\\Salinas_corrected.mat\")[\"salinas_corrected\"]\n",
    "sali_gt = sio.loadmat(r\"E:\\Hyperspectral Image Datasets\\ehu_datasets\\Salinas_gt.mat\")[\"salinas_gt\"]\n",
    "\n",
    "# bay_2013 = sio.loadmat(r\"E:\\Hyperspectral Image Datasets\\change_detec\\Bay_Area_2013.mat\")[\"HypeRvieW\"]\n",
    "# bay_2015 = sio.loadmat(r\"E:\\Hyperspectral Image Datasets\\change_detec\\Bay_Area_2015.mat\")[\"HypeRvieW\"]\n",
    "# #bay_ch_gt_1 = sio.loadmat(r\"E:\\bayArea_gtChanges.mat\")\n",
    "# bay_ch_gt_2 = sio.loadmat(r\"E:\\Hyperspectral Image Datasets\\change_detec\\bayArea_gtChanges2.mat\")['HypeRvieW']\n",
    "# bay_ch_gt_ol = sio.loadmat(r\"E:\\Hyperspectral Image Datasets\\change_detec\\bayArea_gtChangesolf.mat\")['HypeRvieW']\n",
    "# river_before = sio.loadmat(r\"C:\\Users\\CVR 2019 2020\\hyperspectral_custom\\Change-Detection-in-Hyperspectral-Images\\Dataset\\river_before.mat\")['river_before']\n",
    "# river_after = sio.loadmat(r\"C:\\Users\\CVR 2019 2020\\hyperspectral_custom\\Change-Detection-in-Hyperspectral-Images\\Dataset\\river_after.mat\")['river_after']\n",
    "# river_ch_gt = sio.loadmat(r\"C:\\Users\\CVR 2019 2020\\hyperspectral_custom\\Change-Detection-in-Hyperspectral-Images\\Dataset\\groundtruth.mat\")['lakelabel_v1']\n",
    "\n",
    "# data1_2009 = sio.loadmat(r\"E:\\Hyperspectral Image Datasets\\change_detec\\Dataset#1_2009.mat\")['Data2009']\n",
    "# data1_2015 = sio.loadmat(r\"E:\\Hyperspectral Image Datasets\\change_detec\\Dataset#1_2015.mat\")['Data2015']\n",
    "# data1_ch_gt = sio.loadmat(r\"E:\\Hyperspectral Image Datasets\\change_detec\\Dataset#1_GT.mat\")['GT_end']\n",
    "# data2_2009 = sio.loadmat(r\"E:\\Hyperspectral Image Datasets\\change_detec\\Dataset#2_2009.mat\")[\"Data2009\"]\n",
    "# data2_2015 = sio.loadmat(r\"E:\\Hyperspectral Image Datasets\\change_detec\\Dataset#2_2015.mat\")[\"Data2015\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of entry  0 : \n",
      "(610, 340, 103)\n",
      "Size of entry  1 : \n",
      "(610, 340)\n",
      "Size of entry  2 : \n",
      "(1096, 715, 102)\n",
      "Size of entry  3 : \n",
      "(1096, 715)\n",
      "Size of entry  4 : \n",
      "(512, 217, 204)\n",
      "Size of entry  5 : \n",
      "(512, 217)\n"
     ]
    }
   ],
   "source": [
    "u = 0;\n",
    "for i in [pavU, pavU_gt, pavC, pavC_gt, sali, sali_gt]:\n",
    "    print(\"Size of entry \", u, \": \");\n",
    "    print(i.shape)\n",
    "    u = u+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Elements and their counts in entry  12 : \n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([164624,   6631,  18649,   2099,   3064,   1345,   5029,   1330,\n",
      "         3682,    947], dtype=int64))\n",
      "Unique Elements and their counts in entry  13 : \n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([635488,  65971,   7598,   3090,   2685,   6584,   9248,   7287,\n",
      "        42826,   2863], dtype=int64))\n",
      "Unique Elements and their counts in entry  14 : \n",
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16],\n",
      "      dtype=uint8), array([56975,  2009,  3726,  1976,  1394,  2678,  3959,  3579, 11271,\n",
      "        6203,  3278,  1068,  1927,   916,  1070,  7268,  1807],\n",
      "      dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "for i in [paviaU_gt, paviaC_gt, sali_gt]:\n",
    "    print(\"Unique Elements and their counts in entry \", u, \": \");\n",
    "    print(np.unique(i, return_counts=True))\n",
    "    u = u+1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-max normalization ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pavU = ((pavU - pavU.min()) / (pavU.max() - pavU.min()))\n",
    "pavC = ((pavC - pavC.min()) / (pavC.max() - pavC.min()))\n",
    "sali = ((sali - sali.min()) / (sali.max() - sali.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_with_zeros(X, margin_x, margin_y):\n",
    "    \"\"\"apply zero padding to X with margin only the end of the rows and cols\"\"\"\n",
    "    \n",
    "    new_X = np.zeros(((X.shape[0] + margin_x), (X.shape[1] + margin_y), X.shape[2]))\n",
    "    new_X[:X.shape[0], :X.shape[1], :] = X\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_gt_zeros(X, margin_x, margin_y):\n",
    "    \"\"\"apply zero padding to X with margin only the end of the rows and cols\"\"\"\n",
    "    \n",
    "    new_X = np.zeros(((X.shape[0] + margin_x), (X.shape[1] + margin_y)))\n",
    "    new_X[:X.shape[0], :X.shape[1]] = X\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cat_patches(paths, name, array, stride):\n",
    "    x_steps = math.ceil(((array.shape[0]-64)/stride)+1); #Total number of steps by patches without losing anything\n",
    "    y_steps = math.ceil(((array.shape[1]-64)/stride)+1); #Total number of steps by patches without losing anything\n",
    "    margin_x = ((stride * (x_steps-1))+64) - array.shape[0] + 1; # Plus one extra space is required \n",
    "    margin_y = ((stride * (y_steps-1))+64) - array.shape[1] + 1; # Plus one extra space is required \n",
    "    if (len(array.shape) > 2): padded = pad_with_zeros(array, margin_x, margin_y)\n",
    "    else: padded = pad_gt_zeros(array, margin_x, margin_y)\n",
    "    padded = tf.keras.utils.to_categorical(padded, num_classes=np.unique(array).shape[0])\n",
    "    print(padded.shape)\n",
    "    counter = 0;\n",
    "    for r in range(0, padded.shape[0]-64, stride):#r is row       \n",
    "        for c in range(0, padded.shape[1]-64, stride):#c is col \n",
    "            patch = padded[r:r+64, c:c+64];\n",
    "            np.save(pathlib.Path(paths, '{:04d}'.format(counter)).with_suffix(\".npy\"), patch);\n",
    "            counter= counter+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_final_patches(paths, name, array, stride):\n",
    "    x_steps = math.ceil(((array.shape[0]-64)/stride)+1); #Total number of steps by patches without losing anything\n",
    "    y_steps = math.ceil(((array.shape[1]-64)/stride)+1); #Total number of steps by patches without losing anything\n",
    "    margin_x = ((stride * (x_steps-1))+64) - array.shape[0] + 1; # Plus one extra space is required \n",
    "    margin_y = ((stride * (y_steps-1))+64) - array.shape[1] + 1; # Plus one extra space is required \n",
    "    if (len(array.shape) > 2): padded = pad_with_zeros(array, margin_x, margin_y)\n",
    "    else: padded = pad_gt_zeros(array, margin_x, margin_y)\n",
    "    print(padded.shape)\n",
    "    counter = 0;\n",
    "    for r in range(0, padded.shape[0]-64, stride):#r is row       \n",
    "        for c in range(0, padded.shape[1]-64, stride):#c is col \n",
    "            patch = padded[r:r+64, c:c+64];\n",
    "            np.save(pathlib.Path(paths, '{:05d}'.format(counter)).with_suffix(\".npy\"), patch);\n",
    "            counter= counter+1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Hermiston 2004 and 2007 patches - with stride 5 and 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1105, 725, 102)\n",
      "(1153, 769, 102)\n"
     ]
    }
   ],
   "source": [
    "save_final_patches(r\"E:\\intermediate_notebooks\\pavC_2\", \"pavC\", pavC, 10)\n",
    "save_final_patches(r\"E:\\intermediate_notebooks\\pavC_2_final\", \"hermi_2004\", pavC, 64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 345, 103)\n",
      "(641, 385, 103)\n"
     ]
    }
   ],
   "source": [
    "save_final_patches(r\"E:\\intermediate_notebooks\\pavU_2\", \"pavC\", pavU, 5)\n",
    "save_final_patches(r\"E:\\intermediate_notebooks\\pavU_2_final\", \"hermi_2004\", pavU, 64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(515, 218, 204)\n",
      "(513, 257, 204)\n"
     ]
    }
   ],
   "source": [
    "save_final_patches(r\"E:\\intermediate_notebooks\\sali_2\", \"pavC\", sali, 3)\n",
    "save_final_patches(r\"E:\\intermediate_notebooks\\sali_2_final\", \"hermi_2004\", sali, 64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1105, 725, 10)\n",
      "(1153, 769, 10)\n"
     ]
    }
   ],
   "source": [
    "save_cat_patches(r\"E:\\intermediate_notebooks\\pavC_2_gt_cat\", \"hermi_ch_gt_cat\", pavC_gt, 10)\n",
    "save_cat_patches(r\"E:\\intermediate_notebooks\\pavC_2_gt_cat_final\", \"hermi_ch_gt_cat\", pavC_gt, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 345, 10)\n",
      "(641, 385, 10)\n"
     ]
    }
   ],
   "source": [
    "save_cat_patches(r\"E:\\intermediate_notebooks\\pavU_2_gt_cat\", \"hermi_ch_gt_cat\", pavU_gt, 5)\n",
    "save_cat_patches(r\"E:\\intermediate_notebooks\\pavU_2_gt_cat_final\", \"hermi_ch_gt_cat\", pavU_gt, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(515, 218, 17)\n",
      "(513, 257, 17)\n"
     ]
    }
   ],
   "source": [
    "save_cat_patches(r\"E:\\intermediate_notebooks\\sali_2_gt_cat\", \"hermi_ch_gt_cat\", sali_gt, 3)\n",
    "save_cat_patches(r\"E:\\intermediate_notebooks\\sali_2_gt_cat_final\", \"hermi_ch_gt_cat\", sali_gt, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Barbara 2013 and 2014 patches - with stride 20 and 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(985, 745, 224)\n",
      "(1025, 769, 224)\n"
     ]
    }
   ],
   "source": [
    "save_final_patches(r\"E:\\intermediate_notebooks\\bar2013\", \"bar2013\", bar_2013_re, 20)\n",
    "save_final_patches(r\"E:\\intermediate_notebooks\\bar2013_final\", \"bar2013\", bar_2013_re, 64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(985, 745, 224)\n",
      "(1025, 769, 224)\n"
     ]
    }
   ],
   "source": [
    "save_final_patches(r\"E:\\intermediate_notebooks\\bar2014\", \"bar2014\", bar_2014_re, 20)\n",
    "save_final_patches(r\"E:\\intermediate_notebooks\\bar2014_final\", \"bar2014\", bar_2014_re, 64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(985, 745, 3)\n",
      "(1025, 769, 3)\n",
      "(1025, 769)\n"
     ]
    }
   ],
   "source": [
    "save_cat_patches(r\"E:\\intermediate_notebooks\\bar_ch_gt_cat\", \"bar_ch_gt_cat\", bar_ch_gt, 20)\n",
    "save_cat_patches(r\"E:\\intermediate_notebooks\\bar_ch_gt_cat_final\", \"bar_ch_gt_cat\", bar_ch_gt, 64)\n",
    "save_final_patches(r\"E:\\intermediate_notebooks\\bar_ch_gt_final\", \"bar_ch_gt\", bar_ch_gt, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create patches from two images ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_differing_patches(paths, name, array1, array2, stride):\n",
    "    x_steps = math.ceil(((array1.shape[0]-64)/stride)+1); #Total number of steps by patches without losing anything\n",
    "    y_steps = math.ceil(((array1.shape[1]-64)/stride)+1); #Total number of steps by patches without losing anything\n",
    "    margin_x = ((stride * (x_steps-1))+64) - array1.shape[0] + 1; # Plus one extra space is required \n",
    "    margin_y = ((stride * (y_steps-1))+64) - array1.shape[1] + 1; # Plus one extra space is required \n",
    "    if (len(array1.shape) > 2): \n",
    "        padded1 = pad_with_zeros(array1, margin_x, margin_y)\n",
    "        padded2 = pad_with_zeros(array2, margin_x, margin_y)\n",
    "        print(\"Received HSI cube!\")\n",
    "    else: padded = pad_gt_zeros(array, margin_x, margin_y)\n",
    "    print(padded1.shape)\n",
    "    print(padded2.shape)\n",
    "    counter = 0;\n",
    "    for r in range(0, padded1.shape[0]-64, stride):#r is row       \n",
    "        for c in range(0, padded1.shape[1]-64, stride):#c is col \n",
    "            patch1 = padded1[r:r+64, c:c+64];\n",
    "            patch2 = padded2[r:r+64, c:c+64];\n",
    "            np.save(pathlib.Path(paths, '{:04d}'.format(counter)).with_suffix(\".npy\"), patch1);\n",
    "            counter= counter+1;\n",
    "            np.save(pathlib.Path(paths, '{:04d}'.format(counter)).with_suffix(\".npy\"), patch2);\n",
    "            counter= counter+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received HSI cube!\n",
      "(393, 201, 242)\n",
      "(393, 201, 242)\n"
     ]
    }
   ],
   "source": [
    "save_differing_patches(r\"E:\\intermediate_notebooks\\hermi_combined\", \"hermi_combined\", hermi_2004_re, hermi_2007_re, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received HSI cube!\n",
      "(995, 755, 224)\n",
      "(995, 755, 224)\n"
     ]
    }
   ],
   "source": [
    "save_differing_patches(r\"E:\\intermediate_notebooks\\bar_combined\", \"hermi_combined\", bar_2013_re, bar_2014_re, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
